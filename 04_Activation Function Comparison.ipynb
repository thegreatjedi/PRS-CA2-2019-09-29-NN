{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Layer Activation Function Comparison\n",
    "\n",
    "In standard VGG-Net architectures, ReLU activation is used. This \n",
    "notebook will explore whether other functions would give our model\n",
    "better performance.\n",
    "\n",
    "We shall look at the ReLU, Sigmoid, and Tanh functions. For simplicity,\n",
    "we shall constrain all convolutional layers to share the same activation \n",
    "function, and the same goes for the hidden dense layers. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gc import collect\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from h5py import File\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "    confusion_matrix\n",
    "from tensorflow.config.experimental import list_physical_devices, \\\n",
    "    set_memory_growth\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import CSVLogger, LearningRateScheduler, \\\n",
    "    ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input, MaxPool2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.random import set_random_seed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Creation Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(input_shape: Tuple[int, int, int], num_classes: int, \n",
    "                 conv_activation: str = \"relu\", \n",
    "                 dense_activation: str = \"relu\") -> Model:\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    layer = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(inputs)\n",
    "    layer = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "\n",
    "    layer = Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=conv_activation, kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=4096, activation=dense_activation, \n",
    "                  kernel_initializer=\"he_normal\",\n",
    "                  bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Dense(units=4096, activation=dense_activation, \n",
    "                  kernel_initializer=\"he_normal\",\n",
    "                  bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Dense(num_classes, activation=\"softmax\")(layer)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Other Functions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def refresh_session():\n",
    "    # Call this before training a new model, to free up memory from the \n",
    "    # previous model\n",
    "    clear_session()\n",
    "    try:\n",
    "        del model\n",
    "    except NameError:\n",
    "        pass\n",
    "    collect()\n",
    "    \n",
    "    \n",
    "def import_dataset(filepath: str = \"./dataset.hdf5\") \\\n",
    "        -> Tuple[np.ndarray, np.ndarray, np.ndarray, \n",
    "                 np.ndarray, np.ndarray, np.ndarray]:\n",
    "    file = File(filepath, \"r\")\n",
    "    train_data = file.get(\"tr_data\")[()]\n",
    "    val_data = file.get(\"val_data\")[()]\n",
    "    test_data = file.get(\"ts_data\")[()]\n",
    "    train_labels = file.get(\"tr_labels\")[()]\n",
    "    val_labels = file.get(\"val_labels\")[()]\n",
    "    test_labels = file.get(\"ts_labels\")[()]\n",
    "    \n",
    "    return train_data, val_data, test_data, \\\n",
    "           train_labels, val_labels, test_labels\n",
    "\n",
    "\n",
    "def get_test_results(test_model: Model, test_data: np.ndarray, \n",
    "                     test_labels: np.ndarray) -> Tuple:\n",
    "    predicts = test_model.predict(test_data)\n",
    "    pred_out = np.argmax(predicts, axis=1)\n",
    "    test_out = np.argmax(test_labels, axis=1)\n",
    "    labels = [\"car\", \"heavy vehicles\", \"motorcycle\"]\n",
    "    \n",
    "    return accuracy_score(test_out, pred_out), \\\n",
    "           confusion_matrix(test_out, pred_out), \\\n",
    "           classification_report(test_out, pred_out, target_names=labels)\n",
    "\n",
    "\n",
    "def get_learn_rate(epoch: int) -> float:\n",
    "    if epoch <= 10:\n",
    "        lr = 1e-4\n",
    "    elif epoch <= 20:\n",
    "        lr = 5e-5\n",
    "    elif epoch <= 30:\n",
    "        lr = 1e-5\n",
    "    elif epoch <= 40:\n",
    "        lr = 5e-6\n",
    "    else:\n",
    "        lr = 1e-6\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    \n",
    "    return lr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialise Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure tensorflow to optimise GPU utilisation\n",
    "gpu_list = list_physical_devices(\"GPU\")\n",
    "for gpu in gpu_list:\n",
    "    set_memory_growth(gpu, True)\n",
    "del gpu_list\n",
    "\n",
    "# Fix tensorflow random seed\n",
    "set_random_seed(324)\n",
    "\n",
    "tr_dat, val_dat, ts_dat, tr_lbls, val_lbls, ts_lbls = import_dataset()\n",
    "\n",
    "in_shape = (tr_dat.shape[1], tr_dat.shape[2], tr_dat.shape[3])\n",
    "num_cls = tr_lbls.shape[1]\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(get_learn_rate)\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, \n",
    "                              mode=\"min\", restore_best_weights=True) \n",
    "\n",
    "# Test data is not needed in this notebook, so free up the memory\n",
    "del ts_dat\n",
    "del ts_lbls\n",
    "collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Creation and Training\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tanh conv activation\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "conv_activation = \"tanh\"\n",
    "model = create_model(in_shape, num_cls, conv_activation=conv_activation)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/tanh_conv_activation_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/tanh_conv_activation_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sigmoid conv activation\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "conv_activation = \"sigmoid\"\n",
    "model = create_model(in_shape, num_cls, conv_activation=conv_activation)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/sigmoid_conv_activation_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/sigmoid_conv_activation_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tanh dense activation\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "dense_activation = \"tanh\"\n",
    "model = create_model(in_shape, num_cls, dense_activation=dense_activation)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"./trained_models/tanh_dense_activation_best.hdf5\", monitor=\"val_loss\", \n",
    "    verbose=0, save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/tanh_dense_activation_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sigmoid dense activation\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "dense_activation = \"sigmoid\"\n",
    "model = create_model(in_shape, num_cls, dense_activation=dense_activation)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"./trained_models/sigmoid_dense_activation_best.hdf5\", monitor=\"val_loss\", \n",
    "    verbose=0, save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/sigmoid_dense_activation_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training phase is complete: free training data memory\n",
    "del tr_dat\n",
    "del tr_lbls\n",
    "refresh_session()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Visualisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc_scores = dict()\n",
    "conf_matrices = dict()\n",
    "class_reports = dict()\n",
    "\n",
    "plt.style.use(\"ggplot\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# relu baseline\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/vgg13_best.hdf5\")\n",
    "acc_scores[\"relu\"], conf_matrices[\"relu\"], \\\n",
    "class_reports[\"relu\"] = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(\"Validation accuracy for baseline relu activation: \"\n",
    "      f\"{acc_scores['relu']}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[\"relu\"])\n",
    "print(class_reports[\"relu\"])\n",
    "\n",
    "log_relu = read_csv(\"./training_logs/vgg13_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_relu[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_relu[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_relu[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_relu[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_relu[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_relu[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tanh conv activation\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/tanh_conv_activation_best.hdf5\")\n",
    "acc_scores[\"tanh_conv\"], conf_matrices[\"tanh_conv\"], \\\n",
    "class_reports[\"tanh_conv\"] = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(\"Validation accuracy for tanh conv activation: \"\n",
    "      f\"{acc_scores['tanh_conv']}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[\"tanh_conv\"])\n",
    "print(class_reports[\"tanh_conv\"])\n",
    "\n",
    "log_tanh_conv = read_csv(\"./training_logs/tanh_conv_activation_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_tanh_conv[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_tanh_conv[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_tanh_conv[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_tanh_conv[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_tanh_conv[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_tanh_conv[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# sigmoid conv activation\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/sigmoid_conv_activation_best.hdf5\")\n",
    "acc_scores[\"sigmoid_conv\"], conf_matrices[\"sigmoid_conv\"], \\\n",
    "class_reports[\"sigmoid_conv\"] = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(\"Validation accuracy for sigmoid conv activation: \"\n",
    "      f\"{acc_scores['sigmoid_conv']}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[\"sigmoid_conv\"])\n",
    "print(class_reports[\"sigmoid_conv\"])\n",
    "\n",
    "log_sigmoid_conv = read_csv(\"./training_logs/sigmoid_conv_activation_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_sigmoid_conv[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_sigmoid_conv[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_sigmoid_conv[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_sigmoid_conv[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_sigmoid_conv[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_sigmoid_conv[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tanh dense activation\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/tanh_dense_activation_best.hdf5\")\n",
    "acc_scores[\"tanh_dense\"], conf_matrices[\"tanh_dense\"], \\\n",
    "class_reports[\"tanh_dense\"] = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(\"Validation accuracy for tanh dense activation: \"\n",
    "      f\"{acc_scores['tanh_dense']}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[\"tanh_dense\"])\n",
    "print(class_reports[\"tanh_dense\"])\n",
    "\n",
    "log_tanh_dense = read_csv(\"./training_logs/tanh_dense_activation_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_tanh_dense[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_tanh_dense[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_tanh_dense[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_tanh_dense[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_tanh_dense[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_tanh_dense[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sigmoid dense activation\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/sigmoid_dense_activation_best.hdf5\")\n",
    "acc_scores[\"sigmoid_dense\"], conf_matrices[\"sigmoid_dense\"], \\\n",
    "class_reports[\"sigmoid_dense\"] = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(\"Validation accuracy for sigmoid dense activation: \"\n",
    "      f\"{acc_scores['sigmoid_dense']}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[\"sigmoid_dense\"])\n",
    "print(class_reports[\"sigmoid_dense\"])\n",
    "\n",
    "log_sigmoid_dense = read_csv(\"./training_logs/sigmoid_dense_activation_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_sigmoid_dense[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_sigmoid_dense[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_sigmoid_dense[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_sigmoid_dense[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_sigmoid_dense[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_sigmoid_dense[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cross-Model Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 7.5])\n",
    "plt.subplot(211)\n",
    "plt.plot(log_relu[\"val_loss\"], label=\"relu baseline\")\n",
    "plt.plot(log_sigmoid_conv[\"val_loss\"], label=\"sigmoid conv\")\n",
    "plt.plot(log_tanh_conv[\"val_loss\"], label=\"tanh conv\")\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(log_relu[\"val_acc\"], label=\"relu baseline\")\n",
    "plt.plot(log_sigmoid_conv[\"val_acc\"], label=\"sigmoid conv\")\n",
    "plt.plot(log_tanh_conv[\"val_acc\"], label=\"tanh conv\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 7.5])\n",
    "plt.subplot(211)\n",
    "plt.plot(log_relu[\"val_loss\"], label=\"relu baseline\")\n",
    "plt.plot(log_sigmoid_dense[\"val_loss\"], label=\"sigmoid dense\")\n",
    "plt.plot(log_tanh_dense[\"val_loss\"], label=\"tanh dense\")\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(log_relu[\"val_acc\"], label=\"relu baseline\")\n",
    "plt.plot(log_sigmoid_dense[\"val_acc\"], label=\"sigmoid dense\")\n",
    "plt.plot(log_tanh_dense[\"val_acc\"], label=\"tanh dense\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
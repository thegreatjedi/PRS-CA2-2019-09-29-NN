{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Layer Output Filter Count Comparison\n",
    "\n",
    "In standard VGG-Net architectures, one general design guideline is that\n",
    "consecutive convolutional layers have the same number of filters, while\n",
    "for convolutional layers that follow a max pooling layer,\n",
    "\n",
    "- No. filters = Prev. pool. layer's window size * prev. conv. layer's \n",
    "no. filters  \n",
    "\n",
    "In this notebook, we shall continue to follow these guidelines wherever\n",
    "they are observed in the baseline architecture we selected. Thus, we\n",
    "shall only compare between different values of output filter counts for\n",
    "the first convolutional layer, given its ripple effect on the rest of \n",
    "the model.\n",
    "\n",
    "In the standard VGG-13 architecture, the starting output filter count is\n",
    "64. We shall compare between the powers of 2, from 16 to 64.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gc import collect\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from h5py import File\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "    confusion_matrix\n",
    "from tensorflow.config.experimental import list_physical_devices, \\\n",
    "    set_memory_growth\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import CSVLogger, LearningRateScheduler, \\\n",
    "    ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input, MaxPool2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.random import set_random_seed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Creation Function\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# VGG-13\n",
    "def create_model(input_shape: Tuple[int, int, int], num_classes: int,\n",
    "                 num_start_filters: int = 64) -> Model:\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    layer = Conv2D(filters=num_start_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   bias_initializer=\"he_normal\")(inputs)\n",
    "    layer = Conv2D(filters=num_start_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    new_num_filters = num_start_filters * 2\n",
    "\n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    new_num_filters = new_num_filters * 2\n",
    "\n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    new_num_filters = new_num_filters * 2\n",
    "\n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=new_num_filters, kernel_size=(3, 3), strides=1, \n",
    "                   padding=\"same\", activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=4096, activation=\"relu\", \n",
    "                  kernel_initializer=\"he_normal\",\n",
    "                  bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Dense(units=4096, activation=\"relu\", \n",
    "                  kernel_initializer=\"he_normal\",\n",
    "                  bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Dense(num_classes, activation=\"softmax\")(layer)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Other Functions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def refresh_session():\n",
    "    # Call this before training a new model, to free up memory from the \n",
    "    # previous model\n",
    "    clear_session()\n",
    "    try:\n",
    "        del model\n",
    "    except NameError:\n",
    "        pass\n",
    "    collect()\n",
    "    \n",
    "    \n",
    "def import_dataset(filepath: str = \"./dataset.hdf5\") \\\n",
    "        -> Tuple[np.ndarray, np.ndarray, np.ndarray, \n",
    "                 np.ndarray, np.ndarray, np.ndarray]:\n",
    "    file = File(filepath, \"r\")\n",
    "    train_data = file.get(\"tr_data\")[()]\n",
    "    val_data = file.get(\"val_data\")[()]\n",
    "    test_data = file.get(\"ts_data\")[()]\n",
    "    train_labels = file.get(\"tr_labels\")[()]\n",
    "    val_labels = file.get(\"val_labels\")[()]\n",
    "    test_labels = file.get(\"ts_labels\")[()]\n",
    "    \n",
    "    return train_data, val_data, test_data, \\\n",
    "           train_labels, val_labels, test_labels\n",
    "\n",
    "\n",
    "def get_test_results(test_model: Model, test_data: np.ndarray, \n",
    "                     test_labels: np.ndarray) -> Tuple:\n",
    "    predicts = test_model.predict(test_data)\n",
    "    pred_out = np.argmax(predicts, axis=1)\n",
    "    test_out = np.argmax(test_labels, axis=1)\n",
    "    labels = [\"car\", \"heavy vehicles\", \"motorcycle\"]\n",
    "    \n",
    "    return accuracy_score(test_out, pred_out), \\\n",
    "           confusion_matrix(test_out, pred_out), \\\n",
    "           classification_report(test_out, pred_out, target_names=labels)\n",
    "\n",
    "\n",
    "def get_learn_rate(epoch: int) -> float:\n",
    "    if epoch <= 10:\n",
    "        lr = 1e-4\n",
    "    elif epoch <= 20:\n",
    "        lr = 5e-5\n",
    "    elif epoch <= 30:\n",
    "        lr = 1e-5\n",
    "    elif epoch <= 40:\n",
    "        lr = 5e-6\n",
    "    else:\n",
    "        lr = 1e-6\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    \n",
    "    return lr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialise Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure tensorflow to optimise GPU utilisation\n",
    "gpu_list = list_physical_devices(\"GPU\")\n",
    "for gpu in gpu_list:\n",
    "    set_memory_growth(gpu, True)\n",
    "del gpu_list\n",
    "\n",
    "# Fix tensorflow random seed\n",
    "set_random_seed(324)\n",
    "\n",
    "tr_dat, val_dat, ts_dat, tr_lbls, val_lbls, ts_lbls = import_dataset()\n",
    "\n",
    "in_shape = (tr_dat.shape[1], tr_dat.shape[2], tr_dat.shape[3])\n",
    "num_cls = tr_lbls.shape[1]\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(get_learn_rate)\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, \n",
    "                              mode=\"min\", restore_best_weights=True) \n",
    "\n",
    "# Test data is not needed in this notebook, so free up the memory\n",
    "del ts_dat\n",
    "del ts_lbls\n",
    "collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Creation and Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 16 starting filters\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "start_filters = 16\n",
    "model = create_model(in_shape, num_cls, num_start_filters=start_filters)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/16filters_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/16filters_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 32 starting filters\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "start_filters = 32\n",
    "model = create_model(in_shape, num_cls, num_start_filters=start_filters)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/32filters_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/32filters_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training phase is complete: free training data memory\n",
    "del tr_dat\n",
    "del tr_lbls\n",
    "refresh_session()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Visualisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc_scores = dict()\n",
    "conf_matrices = dict()\n",
    "class_reports = dict()\n",
    "\n",
    "plt.style.use(\"ggplot\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 16 starting filters\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/16filters_best.hdf5\")\n",
    "acc_scores[16], conf_matrices[16], class_reports[16] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 16 starting output filters: {acc_scores[16]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[16])\n",
    "print(class_reports[16])\n",
    "\n",
    "log_filter16 = read_csv(\"./training_logs/16filters_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_filter16[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_filter16[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_filter16[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_filter16[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_filter16[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_filter16[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 32 starting filters\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/32filters_best.hdf5\")\n",
    "acc_scores[32], conf_matrices[32], class_reports[32] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 32 starting output filters: {acc_scores[32]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[32])\n",
    "print(class_reports[32])\n",
    "\n",
    "log_filter32 = read_csv(\"./training_logs/32filters_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_filter32[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_filter32[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_filter32[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_filter32[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_filter32[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_filter32[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 64 starting filters - baseline\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/vgg13_best.hdf5\")\n",
    "acc_scores[64], conf_matrices[64], class_reports[64] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 64 starting output filters: {acc_scores[64]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[64])\n",
    "print(class_reports[64])\n",
    "\n",
    "log_filter64 = read_csv(\"./training_logs/vgg13_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_filter64[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_filter64[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_filter64[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_filter64[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_filter64[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_filter64[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cross-Model Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 7.5])\n",
    "plt.subplot(211)\n",
    "plt.plot(log_filter16[\"val_loss\"], label=\"16 filters\")\n",
    "plt.plot(log_filter32[\"val_loss\"], label=\"32 filters\")\n",
    "plt.plot(log_filter64[\"val_loss\"], label=\"64 filters\")\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(log_filter16[\"val_acc\"], label=\"16 filters\")\n",
    "plt.plot(log_filter32[\"val_acc\"], label=\"32 filters\")\n",
    "plt.plot(log_filter64[\"val_acc\"], label=\"64 filters\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dense Layer Unit Count Comparison\n",
    "\n",
    "In standard VGG-Net architectures, the network consists of two hidden \n",
    "dense layers consisting of 4096 units each. This notebook will explore\n",
    "different values to find the best performing value for our model, namely\n",
    "the different powers of 2 from 128 to 4096.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gc import collect\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from h5py import File\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "    confusion_matrix\n",
    "from tensorflow.config.experimental import list_physical_devices, \\\n",
    "    set_memory_growth\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import CSVLogger, LearningRateScheduler, \\\n",
    "    ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Input, MaxPool2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.random import set_random_seed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Creation Function\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# VGG-13\n",
    "def create_model(input_shape: Tuple[int, int, int], num_classes: int,\n",
    "                 num_dense_units: int = 4096) -> Model:\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    layer = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(inputs)\n",
    "    layer = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "\n",
    "    layer = Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", \n",
    "                   activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                   bias_initializer=\"he_normal\")(layer)\n",
    "    layer = MaxPool2D(pool_size=(2, 2), strides=2)(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=num_dense_units, activation=\"relu\", \n",
    "                  kernel_initializer=\"he_normal\",\n",
    "                  bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Dense(units=num_dense_units, activation=\"relu\", \n",
    "                  kernel_initializer=\"he_normal\",\n",
    "                  bias_initializer=\"he_normal\")(layer)\n",
    "    layer = Dense(num_classes, activation=\"softmax\")(layer)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Other Functions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def refresh_session():\n",
    "    # Call this before training a new model, to free up memory from the \n",
    "    # previous model\n",
    "    clear_session()\n",
    "    try:\n",
    "        del model\n",
    "    except NameError:\n",
    "        pass\n",
    "    collect()\n",
    "    \n",
    "    \n",
    "def import_dataset(filepath: str = \"./dataset.hdf5\") \\\n",
    "        -> Tuple[np.ndarray, np.ndarray, np.ndarray, \n",
    "                 np.ndarray, np.ndarray, np.ndarray]:\n",
    "    file = File(filepath, \"r\")\n",
    "    train_data = file.get(\"tr_data\")[()]\n",
    "    val_data = file.get(\"val_data\")[()]\n",
    "    test_data = file.get(\"ts_data\")[()]\n",
    "    train_labels = file.get(\"tr_labels\")[()]\n",
    "    val_labels = file.get(\"val_labels\")[()]\n",
    "    test_labels = file.get(\"ts_labels\")[()]\n",
    "    \n",
    "    return train_data, val_data, test_data, \\\n",
    "           train_labels, val_labels, test_labels\n",
    "\n",
    "\n",
    "def get_test_results(test_model: Model, test_data: np.ndarray, \n",
    "                     test_labels: np.ndarray) -> Tuple:\n",
    "    predicts = test_model.predict(test_data)\n",
    "    pred_out = np.argmax(predicts, axis=1)\n",
    "    test_out = np.argmax(test_labels, axis=1)\n",
    "    labels = [\"car\", \"heavy vehicles\", \"motorcycle\"]\n",
    "    \n",
    "    return accuracy_score(test_out, pred_out), \\\n",
    "           confusion_matrix(test_out, pred_out), \\\n",
    "           classification_report(test_out, pred_out, target_names=labels)\n",
    "\n",
    "\n",
    "def get_learn_rate(epoch: int) -> float:\n",
    "    if epoch <= 10:\n",
    "        lr = 1e-4\n",
    "    elif epoch <= 20:\n",
    "        lr = 5e-5\n",
    "    elif epoch <= 30:\n",
    "        lr = 1e-5\n",
    "    elif epoch <= 40:\n",
    "        lr = 5e-6\n",
    "    else:\n",
    "        lr = 1e-6\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    \n",
    "    return lr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialise Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure tensorflow to optimise GPU utilisation\n",
    "gpu_list = list_physical_devices(\"GPU\")\n",
    "for gpu in gpu_list:\n",
    "    set_memory_growth(gpu, True)\n",
    "del gpu_list\n",
    "\n",
    "# Fix tensorflow random seed\n",
    "set_random_seed(324)\n",
    "\n",
    "tr_dat, val_dat, ts_dat, tr_lbls, val_lbls, ts_lbls = import_dataset()\n",
    "\n",
    "in_shape = (tr_dat.shape[1], tr_dat.shape[2], tr_dat.shape[3])\n",
    "num_cls = tr_lbls.shape[1]\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(get_learn_rate)\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, \n",
    "                              mode=\"min\", restore_best_weights=True) \n",
    "\n",
    "# Test data is not needed in this notebook, so free up the memory\n",
    "del ts_dat\n",
    "del ts_lbls\n",
    "collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Creation and Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 128 dense units\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "model_dense_units = 128\n",
    "model = create_model(in_shape, num_cls, model_dense_units)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/128denseunits_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/128denseunits_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 256 dense units\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "model_dense_units = 256\n",
    "model = create_model(in_shape, num_cls, model_dense_units)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/256denseunits_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/256denseunits_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 512 dense units\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "model_dense_units = 512\n",
    "model = create_model(in_shape, num_cls, model_dense_units)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/512denseunits_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/512denseunits_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1024 dense units\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "model_dense_units = 1024\n",
    "model = create_model(in_shape, num_cls, model_dense_units)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/1024denseunits_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/1024denseunits_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2048 dense units\n",
    "refresh_session()\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=45, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "model_dense_units = 2048\n",
    "model = create_model(in_shape, num_cls, model_dense_units)\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./trained_models/2048denseunits_best.hdf5\", \n",
    "                             monitor=\"val_loss\", verbose=0, \n",
    "                             save_best_only=True, mode=\"min\")\n",
    "logger = CSVLogger(\"./training_logs/2048denseunits_log.csv\")\n",
    "\n",
    "model.fit_generator(\n",
    "    data_gen.flow(tr_dat, tr_lbls, batch_size=32, shuffle=True), \n",
    "    steps_per_epoch=(len(tr_dat) / 32), epochs=50, verbose=2, \n",
    "    callbacks=[checkpoint, logger, lr_scheduler, early_stopper], \n",
    "    validation_data=(val_dat, val_lbls))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training phase is complete: free training data memory\n",
    "del tr_dat\n",
    "del tr_lbls\n",
    "refresh_session()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Visualisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc_scores = dict()\n",
    "conf_matrices = dict()\n",
    "class_reports = dict()\n",
    "\n",
    "plt.style.use(\"ggplot\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 128 dense units\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/128denseunits_best.hdf5\")\n",
    "acc_scores[128], conf_matrices[128], class_reports[128] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 128 dense units: {acc_scores[128]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[128])\n",
    "print(class_reports[128])\n",
    "\n",
    "log_dense128 = read_csv(\"./training_logs/128denseunits_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_dense128[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_dense128[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_dense128[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_dense128[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_dense128[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_dense128[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 256 dense units\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/256denseunits_best.hdf5\")\n",
    "acc_scores[256], conf_matrices[256], class_reports[256] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 256 dense units: {acc_scores[256]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[256])\n",
    "print(class_reports[256])\n",
    "\n",
    "log_dense256 = read_csv(\"./training_logs/256denseunits_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_dense256[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_dense256[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_dense256[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_dense256[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_dense256[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_dense256[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 512 dense units\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/512denseunits_best.hdf5\")\n",
    "acc_scores[512], conf_matrices[512], class_reports[512] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 512 dense units: {acc_scores[512]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[512])\n",
    "print(class_reports[512])\n",
    "\n",
    "log_dense512 = read_csv(\"./training_logs/512denseunits_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_dense512[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_dense512[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_dense512[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_dense512[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_dense512[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_dense512[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1024 dense units\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/1024denseunits_best.hdf5\")\n",
    "acc_scores[1024], conf_matrices[1024], class_reports[1024] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 1024 dense units: {acc_scores[1024]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[1024])\n",
    "print(class_reports[1024])\n",
    "\n",
    "log_dense1024 = read_csv(\"./training_logs/1024denseunits_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_dense1024[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_dense1024[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_dense1024[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_dense1024[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_dense1024[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_dense1024[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2048 dense units\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/2048denseunits_best.hdf5\")\n",
    "acc_scores[2048], conf_matrices[2048], class_reports[2048] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 2048 dense units: {acc_scores[2048]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[2048])\n",
    "print(class_reports[2048])\n",
    "\n",
    "log_dense2048 = read_csv(\"./training_logs/2048denseunits_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_dense2048[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_dense2048[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_dense2048[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_dense2048[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_dense2048[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_dense2048[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4096 dense units\n",
    "# Reuse existing model\n",
    "refresh_session()\n",
    "model = load_model(\"./trained_models/vgg13_best.hdf5\")\n",
    "acc_scores[4096], conf_matrices[4096], class_reports[4096] \\\n",
    "    = get_test_results(model, val_dat, val_lbls)\n",
    "\n",
    "print(f\"Validation accuracy for 4096 dense units: {acc_scores[4096]}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrices[4096])\n",
    "print(class_reports[4096])\n",
    "\n",
    "log_dense4096 = read_csv(\"./training_logs/vgg13_log.csv\")\n",
    "\n",
    "plt.figure(figsize=[12.5, 12.5])\n",
    "plt.subplot(311)\n",
    "plt.plot(log_dense4096[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(log_dense4096[\"val_acc\"], label=\"accuracy\")\n",
    "plt.title(\"Validation\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(log_dense4096[\"loss\"], label=\"train loss\")\n",
    "plt.plot(log_dense4096[\"val_loss\"], label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(log_dense4096[\"acc\"], label=\"train accuracy\")\n",
    "plt.plot(log_dense4096[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cross-Model Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 7.5])\n",
    "plt.subplot(211)\n",
    "plt.plot(log_dense128[\"val_loss\"], label=\"128 units\")\n",
    "plt.plot(log_dense256[\"val_loss\"], label=\"256 units\")\n",
    "plt.plot(log_dense512[\"val_loss\"], label=\"512 units\")\n",
    "plt.plot(log_dense1024[\"val_loss\"], label=\"1024 units\")\n",
    "plt.plot(log_dense2048[\"val_loss\"], label=\"2048 units\")\n",
    "plt.plot(log_dense4096[\"val_loss\"], label=\"4096 units\")\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(log_dense128[\"val_acc\"], label=\"128 units\")\n",
    "plt.plot(log_dense256[\"val_acc\"], label=\"256 units\")\n",
    "plt.plot(log_dense512[\"val_acc\"], label=\"512 units\")\n",
    "plt.plot(log_dense1024[\"val_acc\"], label=\"1024 units\")\n",
    "plt.plot(log_dense2048[\"val_acc\"], label=\"2048 units\")\n",
    "plt.plot(log_dense4096[\"val_acc\"], label=\"4096 units\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}